{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PU learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say that 8 - is positive and all other is negative class\n",
    "digits.target = np.array(digits.target==8, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on properly defined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:3*n_samples // 4], digits.target[:3*n_samples // 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       409\n",
      "           1       1.00      0.83      0.91        41\n",
      "\n",
      "    accuracy                           0.98       450\n",
      "   macro avg       0.99      0.91      0.95       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[409   0]\n",
      " [  7  34]]\n"
     ]
    }
   ],
   "source": [
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[3*n_samples // 4:]\n",
    "predicted = classifier.predict(data[3*n_samples // 4:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create unlabled(undefined) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create labeled/unlabled data\n",
    "digits[\"s\"] = np.random.randint(0,2, len(digits.target))*digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "CL_g = svm.SVC(gamma=0.001, probability=True)\n",
    "\n",
    "CL_g.fit(data[:3*n_samples // 4], digits.s[:3*n_samples // 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       409\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.91       450\n",
      "   macro avg       0.45      0.50      0.48       450\n",
      "weighted avg       0.83      0.91      0.87       450\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[409   0]\n",
      " [ 41   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nectostr\\AppData\\Local\\Continuum\\miniconda3\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[3*n_samples // 4:]\n",
    "predicted = CL_g.predict(data[3*n_samples // 4:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (CL_g, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result on unlabled data with usual classifier is more than unsagnificant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create improvement with weighted train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = [\"x\"+str(i) for i in range(len(data[0]))]\n",
    "df = pd.DataFrame(data, columns=x_columns)\n",
    "df[\"y\"] = digits.target\n",
    "df[\"s\"] = digits.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[x_columns], df[[\"s\", 'y']], test_size=0.33, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_train(e, X_train, y_train, CL):\n",
    "    X_train_new = pd.DataFrame(X_train.loc[y_train.index[y_train[\"s\"] == 1]])\n",
    "    X_train_new[\"w\"] = 1\n",
    "    y_train_new = pd.DataFrame([1]*len(X_train_new), columns=[\"s\"])\n",
    "    X_train_1 = pd.DataFrame(X_train.loc[y_train.index[y_train[\"s\"] == 0]])\n",
    "    g_x = CL.predict_proba(X_train_1[x_columns])[:,1]\n",
    "    X_train_1[\"w\"] = (1-e)/e * g_x/(1-g_x)\n",
    "    y_train_1 = pd.DataFrame([1]*len(X_train_1), columns=[\"s\"])\n",
    "    X_train_2 = pd.DataFrame(X_train.loc[y_train.index[y_train[\"s\"] == 0]])\n",
    "    g_x = CL.predict_proba(X_train_2[x_columns])[:,1]\n",
    "    X_train_2[\"w\"] = 1 - (1-e)/e * g_x/ (1-g_x)\n",
    "    y_train_2 = pd.DataFrame([0]*len(X_train_2), columns=[\"s\"])\n",
    "    X_train_new = X_train_new.append(X_train_1, ignore_index=True, sort=False)\n",
    "    X_train_new = X_train_new.append(X_train_2, ignore_index=True, sort=False)\n",
    "    y_train_new = y_train_new.append(y_train_1, ignore_index=True, sort=False)\n",
    "    y_train_new = y_train_new.append(y_train_2, ignore_index=True, sort=False)\n",
    "    return X_train_new, y_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1 = 0.4940622009601986\n",
      "e2 = 0.5919204879175857\n",
      "e3 = 0.99364475038768\n"
     ]
    }
   ],
   "source": [
    "X_val_p = X_val.loc[X_val.index[y_val[\"s\"] == 1]]\n",
    "d_p = CL_g.predict_proba(X_val_p)[:,1]\n",
    "e1 = d_p.sum()/len(X_val_p)\n",
    "print(f\"e1 = {e1}\")\n",
    "d_v = CL_g.predict_proba(X_val)[:,1]\n",
    "e2 = d_p.sum()/d_v.sum()\n",
    "print(f\"e2 = {e2}\")\n",
    "e3 = d_v.max()\n",
    "print(f\"e3 = {e3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CL_f =  svm.SVC(gamma=0.001, probability=True)\n",
    "X_train_new, y_train_new = create_new_train(e2, X_train, y_train, CL_g)\n",
    "CL_f.fit(X_train_new[x_columns], y_train_new[\"s\"], sample_weight=X_train_new['w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       542\n",
      "           1       1.00      0.37      0.54        52\n",
      "\n",
      "    accuracy                           0.94       594\n",
      "   macro avg       0.97      0.68      0.75       594\n",
      "weighted avg       0.95      0.94      0.93       594\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[542   0]\n",
      " [ 33  19]]\n"
     ]
    }
   ],
   "source": [
    "expected = y_test[\"y\"]\n",
    "predicted = CL_f.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (CL_f, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
